\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{syntax} % Grammar writer
\usepackage{listings} % source code writer
\usepackage[usenames,dvipsnames]{xcolor}

% ----------------------------------------------------------
% Source code syntax highlight
\lstdefinelanguage{Emma}
{morekeywords={print,if,else,while,def,return,for,continue,break,class,null},
morekeywords={import,package,try,raise,catch,finally,elif},
sensitive=false,
morecomment=[l]{\#},
morestring=[b]",
morestring=[b]',
} 

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Emma,
  emph={and,xor,or,not},
  emphstyle=\color{dkgreen},
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=fixed,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{Sepia},
  commentstyle=\color{blue},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
% End of syntax highlight
% ----------------------------------------------------------

\author{Yang Wang}
\date{}
\title{The Emma Language Reference}
\begin{document}
\maketitle
\tableofcontents

\section{Introduction}
This reference manual describes the Emma language and also serves as a  
language specification and development guidance.

The Emma language is a self-education and experimental project. 
The main purpose is for the author to study the theory and best practice related
to compiler design and implementation. 
The final product is envisioned to be a high level programming language similar
to Python in spirit, but also incorporate features from other languages such as
IDL (Interactive Data Language), C, Java. The style of this reference is also
influenced by the Python reference.

The basic target of the language is to be Turning complete. The ultimate
target is to be self-hosting, i.e.\ be able to compile itself.
The current development scope of the language is listed as follows:

\begin{itemize}
\item Functions (with recursive calls)
\item Array support
\item Basic I/O support
\item Object oriented programming support by class definitions
\item Interaction among source files with import
\item Error handling and interactive debugging similar to IDL
\item Interface to use external C libraries
\end{itemize}


\subsection{Implementation}
The language will be prototyped in Python and implemented in C. 
An interactive environment will be provided as well as a batch
run mode. Any programs written in the language will be compiled
to bytecode for execution speed boost. This means
that a runtime environment of the language is always required to run
programs, since there will be no compilation to native machine code.

\subsection{Terminology}
\begin{description}
\item[System] The Emma language runtime environment and its standard library.
\item[Entity] A single program unit such as variable, function, class.
\end{description}

\subsection{Philosophy}
These are the principles for the design, implementation and usage of the language.
\begin{enumerate}
\item No redundant functionalities
\item Be straightforward
\end{enumerate}

\pagebreak

\section{Language Model}

\subsection{File organization}

\subsubsection{Module and package}
A file is a module while a directory containing modules is a package. 
The module name is the file name without the extension.
The package name is just the name of a directory.
Modules and packages have structure hierarchy just like
files and directories. 
We shall use file and module interchangeably in the rest of the reference.

It is recommended to use ``.em'' as the file extension for source file names.
Other extensions can be used. However, \lstinline$import$ and 
\lstinline$package$ assume the ``.em'' extension and hence 
do not work properly for other extensions.
In addition, file and directory names should follow the same naming convention
as variables for \lstinline$import$ and \lstinline$package$ to work.

\subsubsection{The import keyword}
The interoperability among different modules are supported by the 
\lstinline$import$ and \lstinline$package$ mechanisms. 
A module can gain access other module's functionalities by \lstinline$import$
the other module. Following pseudo-code describes the general usage of the
keyword.

\begin{verbatim}
import [ <pkg> . ] <module> [ . <name> ]
\end{verbatim}

Note square brackets indicate that the item in between them is optional.
\verb$<pkg>$ is the package (directory) path of the module (file).
It is allowed to have arbitrary long package path.
\verb$<module>$ is the module name, i.e. the source file name without
the file extension.
\verb$<name>$ is a name, which is either a variable, function or class,
defined in the module file. The asterisk symbol can be used as a wildcard
name to indicate all names in the module are to be imported. 

An \lstinline$import$ statement makes names in a module visible to user code.
When a name is given in the \lstinline$import$ statement, 
it can be referenced without qualifying with its module. 
Otherwise, the full qualified name, e.g. \verb$module.name$ has to been used.
Note the package path is not needed while referencing a name regardless
of the name presence in the \lstinline$import$ statement.

Following code snippets show a few examples how import works.

\begin{lstlisting}[caption=import statement example]
import foo.bar
import foo.bar.baz
bar.qux()
baz()
\end{lstlisting}

In above code fragment, \lstinline$foo$ is a package and 
\lstinline$bar$ is a module. 
The first import has the format of \verb$pkg.module$ and does not have
a name. 
This is why the usage of \lstinline$qux$ function in \lstinline$bar$ 
has to be qualified as \lstinline$bar.qux()$.

The second import has the format of \verb$pkg.module.name$. 
Hence the name \lstinline$baz$ can be used without module qualification.

\begin{lstlisting}[caption=import statement with the wildcard character]
import foo.bar.*
qux()
baz()
\end{lstlisting}

The above import shows the usage of the wildcard character. 
After the import, all names in module bar can be directly used by
user code without qualification.

\subsubsection{The package keyword}
There is one missing piece in the import mechanism described in previous
section.
That is how file search works to locate the requested module.
The \lstinline$package$ keyword can be used to affect the search behavior.

The system uses an internal variable to keep a list of paths for file
searching. By default, the paths include the builtin library directory and
the current working directory. More paths can be added to the search
paths interactively or via configuration file. The current working directory
is always the first entry in the list of paths while the builtin library 
is the last in the list.

A module is searched in the list of paths beginning from the current
working directory. The first match is used and other matches (if any)
are ignored.

A \lstinline$package$ keyword indicates the file is part of
a package, which is some directory one or more level up in the file system
hierarchy. 
Any subsequent import related to this package is to be searched
only in the directory. This is how the \lstinline$package$ keyword
changes the behavior of module searching. 
Following is an example showing code fragment of a file named 
\lstinline$mymodule.em$.

\begin{lstlisting}[caption=Example of the package keyword]
package foo
import foo.bar
import foo.bar.qux
import baz
\end{lstlisting}

The first line declares the file is part of a package \lstinline$foo$.
The package must be a directory one or more level up to the file.
Assume the file's full path name is something like 
\verb$...foo/sub/mymodule.em$. The package is obviously the 
\verb$foo$ directory in the full path name. 
The following two import are related to the package. 
The search will then be conducted in the directory \verb$foo$.
The last import is not related to the package. 
Hence the normal search process will take place by starting with
the current working directory.

The effect of the \lstinline$package$ keyword is, as its name indicates,
useful for package developers.
When a module in the package imports another module in the same
package, it can simply declare the package and start import such as
\lstinline$import $\verb$package.module$ and it will work no matter where
the package itself is located.

\subsection{Data model}
\subsubsection{Types}
In principle, there is only one data type, i.e.\ object.
Everything is of the object type, including literals and functions.
Therefore it is really the class of an object that we
are interested. For convenience, we will use the term ``data type"
when talking about the class. But be aware that it is really 
the class that we are talking about.

The basic data types include integer, float, string, and null. 
Two aggregate data types, list and hash, are also provided via builtin
functions. Both of them are heterogeneous, that is they can have
different data types, including themselves, as their elements. 
Note that the key of a hash can only be one of the basic data types.
There is no dedicate boolean type. 
An empty list, empty hash, empty string, number 0 and a null are all 
evaluated to zero on condition test. Anything else is evaluated to one.

\subsubsection{User defined class}
User defined class can be created from scratch or as a subclass of existing
class. Note that the primitive Object class is used as the top level
superclass even if none is specified. 
Multi-inheritance is not allowed. However, classes can have arbitrary long 
inheritance chains.

Having Object as the top level class provides many useful utilities.
Similar to Python, it has a set of methods, including comparison,
string conversion, boolean test, etc. These default methods can all
be overridden by subclasses. 

\subsection{Name, binding and environment}
We already knew everything is an object in the Emma language. 
Names are associated with objects so that they can be uniquely identified.
A name is simply an identifier in the source code. 
The association created between a name and an object is called binding.
When a variable is created, it is essentially done by
creating a binding between the variable name and its content.

Information about bindings are kept in environment, which works
like an hash indexed by names.
For an example, a module has an environment that keeps all bindings of 
the module.

\subsubsection{Environment and scope}
New environments are created for every module, function and class.
These environments are nested and the top level environment is the one
associated with the top level module, i.e.\ the module being directly
invoked by users. 

The environment also defines the scope and how names are searched during
running time. 
The top level environment defines the global scope. 
At a time, there is only one environment, called the current scope,
at the bottom level of the environment chain.

The names are first searched in the current scope.
If it is not found, it is then searched in the scope that is one
level higher than the current scope. 
The process continues until the name is found or errors out if no match.
New variables will be created in the current scope unless explicitly 
requested to be created in other scopes.

\subsubsection{Internals of object and its binding}
Under the hood, there are only two categories of objects that names
are bound with. 
One is closure and the other is simple object.

A closure is a combination of code object and the environment where
the code object is defined.
A code object is an internal representation of source code of either a 
module, a function or a class.
Note that the code object has the ability to contain other names, which
again may associate with either closure or simple object.

Simple objects represent integer, float, string variables and any literals.
Basically anything that cannot contain other names.



\pagebreak

\section{Lexical analysis}
\subsection{Line structure}
An Emma program is consisted of lines of texts. The line structure is
hence one of the basic component of a source program.

\subsubsection{Physical line}
A physical line is terminated by an end-of-line sequence (EOL). The
sequence is different on different platforms. Unix and alike use ASCII LF
(linefeed), while Windows uses ASCII sequence of CR LF (carriage return followed
by a linefeed). All of these sequences are treated equally as a single 
EOL symbol.

\subsubsection{Logical line}
A logical line can be a single physical line, multiple physical lines, or
part of a single physical line.

A logical line is terminated by either a EOL or a semicolon if the last
statement is a simple one. A compound statement always has a ``\}'' at 
the end, which also works as a logical line termination.

Termination of a logical line by a EOL is the most straightforward choice. 
This makes a physical line to be also a logical line.

A semicolon is supposed to be used in middle of a physical line to separate 
statements. This allows a single physical line to contain multiple logical
lines, which is useful to enter a long script in an interactive session.

The line continuation symbol, ``\textbackslash", joins two physical lines
by effectively ignoring the EOL symbol between them.
This makes it possible to have a logical line span across multiple 
physical lines. 

Simple statements can never cross the boundaries of a logical line.
For compound statements, the language syntax allows both EOL and semicolon
to be in between statements in a ``\{\}'' pair. Therefore compound statements
may be consisted of multiple logical lines. Note that even for a compound 
statement, line termination is still not allowed outside of the 
``\{\}'' pair. 

These rules are better clarified with the following example:

\begin{lstlisting}
# Line termination rules
if (x == 1) {
    y = 1;
} else {
    y = 0
} a = 5; b = 6
\end{lstlisting}

Note that both EOL and semicolon can appear inside the ``\{\}'' pairs. 
But lines cannot be terminated outside of the ``\{\}'' pairs. That is
why the ``\{'' has to be in the same line with ``\lstinline$if (x == 1)$''.
For the same reason, ``\lstinline$else$'' is in the same line with both 
the leading
``\}'' and the ending ``\{''. Also note that the ``\lstinline$a = 5$'' 
statement does
not need a semicolon before it because the previous compound statement
is properly terminated by a ``\}''. In contrast, a semicolon is needed
after it for the following ``\lstinline$b = 6$'' statement.

\subsubsection{Line joining}
The backslash character, ``\textbackslash'', can be used to join two 
physical lines.
This allows a logical line to span across multiple physical lines as follows:
\begin{lstlisting}
# Line joining by "\" character
x = a + b \
      + c \
      + d
\end{lstlisting}

\subsubsection{Comment}
The hash character, ``\#'', starts a single line comment runs to the end
of a physical line. There is currently no plan to support multi-line
comment symbols.

\subsubsection{Blank line and whitespace}
Both space and tab are whitespace. They are used to separate other 
language unit, but are otherwise ignored. Blank lines are ignored.

\subsection{Keyword and identifier}
Keywords are reserved and listed as follows\footnote{Keyword operators 
are shown in green color while normal keywords are shown in sepia. It is 
completely cosmetic with no impact on the language.}:
\begin{lstlisting}
print    if      elif  else   while   for      break  def   
continue return  null  class  import  package  try    raise
catch    finally and   or     xor 
\end{lstlisting}

An identifier is a character sequence starts with a letter or an underscore 
and followed by zero or more letters, numbers or underscore and it cannot
be any of the reserved keywords.

\subsubsection{Speical identifier}
A special identifier, ``_'' (without the quotes), always points
to the value of last unused expression.
\begin{lstlisting}
# Speical identifier
1 + 1
a = 2 + 2
print 3 + 3
\end{lstlisting}
At the end of the above code snippet, the value of ``_'' is 2. This is because 
both \lstinline$2 + 2$ and \lstinline$3 + 3$ are used by an assignment and
a print statement, respectively. User can directly assign a value to the special
identifier. In doing so, any value it held previously is overwritten.

\subsection{Number}
Numbers only come in two types, integer and floating point numbers.
Both numbers can be arbitrary large as long as the computer memory
can hold them. Only decimal numbers are supported. Floating point
number can be written in scientific notation form, e.g. 1.0e+20.

\subsection{Operator}
Certain keywords are also operators, such as \lstinline$and$, 
\lstinline$or$, \lstinline$xor$, \lstinline$not$. Other operators
includes mathematical operators and symbols for aiding formation
of language structs. They are show as follows:
\begin{lstlisting}
+ - * / % ** ( ) { } [ ] , : ;
\end{lstlisting}
Note that the unprintable EOL symbol is not shown in the above list,
though it is also an operator. 

\subsection{Token}
Tokens are recognized and returned by a lexer. A token can be a keyword,
an identifier, a number or an operator. The token definitions are listed
as follows:

\begin{verbatim}
IDENT       ::= (Letter| Underscore) 
                    (Letter | Digit | Underscore)*

STRING      ::= "Valid_Ascii_Sequence" | 'Valid_Ascii_Sequence'

KEYWORD     ::= print | if | else | for | while | continue 
              | break | def | class | and | or | xor | not
              
NUMBER      ::= [+ | -] Pos_Number

Pos_Number  ::= [0-9]+ 
              | [0-9]* . [0-9]+ [Expo] 
              | [0-9]+ . [0-9]* [Expo]

Expo        ::= e [+ | -] [0-9]+
\end{verbatim}

Note that only full capitalized words are tokens. Camel case words
are only here to aid reading and clarity. 
Operators and other characters are returned as tokens named by their lexme.

\subsection{Lexer}
A lexer reads the input source file and generate tokens based on 
the input character stream. The lexer return one token every time
it is called. A symbol table is used to reserve keywords and save
identifier information.

\pagebreak


\section{Syntax analysis}
A parser does the syntax analysis of source code and produce a parse tree
as its output. The parser calls the lexer for a stream of tokens and 
analyze them with a grammar.

\subsection{grammar}
The grammar is of the LL(1) class, which can be parsed by a hand written 
predictive recursive descendant parser. 
A grammar $G$ is LL(1) if and only if whenever $A \rightarrow \alpha\ |\ \beta$ 
are two distinct productions of $G$, the following conditions hold:
\begin{itemize}
\item FIRST($\alpha$) and FIRST($\beta$) are disjoint sets. This also indicates
at most one of $\alpha$ and $\beta$ can derive the empty string.
\item If $\varepsilon$ is in FIRST($\alpha$), then FIRST($\beta$) and 
FOLLOW($A$) are disjoint sets.
\end{itemize}

The BNF notations of the Emma language grammar are shown as follows:
\footnote{
The grammar shown here does have left recursive terms and they
can be sysmatically eliminated during the parser writing. They
are however shown here because it is more concise and easy to
read.}

\setlength{\grammarparsep}{10pt plus 1pt minus 1pt} % increase separation between rules
\setlength{\grammarindent}{12em} % increase separation between LHS/RHS 
\begin{grammar}

% We could let lexer to do more work on merge consecutive ';' as a single ';'

<program> ::= <statement>*

<statement> ::= "EOL" 
    \alt <stmt_list> [`;'] "EOL"

<stmt_list> ::= <simple_stmt_list> | <compound_stmt_list>

<simple_stmt_list> ::= <simple_stmt> [ `;' <list_rest> ]

<compound_stmt_list> ::= <compound_stmt> [`;'] [ <list_rest> ]

<list_rest> ::= <smiple_stmt_list> 
    \alt <compound_stmt_list>

<stmt> ::= <simple_stmt> 
    \alt <stmt_block>

<stmt_block> ::= `{' <statement>* [<stmt_list>] "EOL"* `}'

<compound_stmt> ::= <if_stmt>
	\alt <while_stmt>
	\alt <for_stmt>
	\alt <funcdef>
    \alt <classdef>
    \alt <try_stmt>

% we may NOT want a compound stmt following something like 'if 1'
% so we might have to split, say, if_stmt into 	if_simple_stmt 
% and if_compound_stmt
<if_stmt> ::= `if' <expression> <stmt> [`elif' <stmt>] [`else' <stmt>]
              
<while_stmt> ::= `while' <expression> <stmt>

<for_stmt> ::= `for' "IDENT" `=' <for_expr> <stmt>

<for_expr> ::= <expression> `,' <expression> [`,' <expression>]

<oparm_list> ::= <oparm> (`,' <oparm>)*

<oparm> ::= <kvpair> | "IDENT"

<parmlist> ::= <oparm_list> [`,' `*' "IDENT"] [`,' `**' "IDENT"]
    \alt `*' "IDENT" [`,' `**' "IDENT"]
    \alt `**' "IDENT"

<funcdef> ::= `def' "IDENT" `(' [<parmlist>] `)' <stmt>

<classdef> ::= `class' "IDENT" `(' "IDENT" `)' <stmt>

<try_stmt> ::= `try' <stmt> (<catch>)$^{+}$ [<finally>]

<catch> ::= `catch' `(' "IDENT" "IDENT" `)' <stmt>

<finally> ::= `finally' <stmt>

<simple_stmt> ::= <expression>
	\alt <assign_stmt>                    
	\alt <print_stmt>
	\alt `continue'
	\alt `break'
	\alt `return' <expression>
	
<print_stmt> ::= `print' [expression (`,' <expression>)*]

<target> ::= "IDENT" | <dotname> | <slice>

<assign_stmt> ::= <target> `=' <expression>

<r_orop> ::= `or' | `xor'

<r_andop> ::= `and'

<l_op> ::= `>' | `<' | `>=' | `<=' | `==' | `!='

<addop> ::= `+' | `-'

<mulop> ::= `*' | `/' | `\%'

<unary_op> ::= `+' | `-'

<expression> ::= <r_expr>

<r_expr> ::= <r_term> (<r_orop> <r_term>)*

<r_term> ::= <r_factor> (<r_andop> <r_factor>)*

<r_factor> ::= [`not'] <l_expression>

<l_expr> ::= <a_expr> (<l_op> <a_expr>)*

<a_expr> ::= <a_term> (<addop> <a_term>)*

<a_term> ::= <u_expr> (<mulop> <u_expr>)*

<u_expr> ::= [<unary_op>] <power>

<power> ::= <factor> [`**' <u_expr>]

<literal> ::= "STRING" | "NUMBER" | "NULL"

<factor> ::= <primary> | <literal> | `(' <expression> `)'

<kvpair> ::= "IDENT" `=' <expression>

<oarg> ::= <kvpair> | <expression>

<arglist> ::= <oarg> (`,' <oarg>)*

<call> ::= <primary> `(' [<arglist>] `)'

<idxlist> ::= <singleidx> (`,' <expression>)*

<long_idxrange> ::= <short_idxrange> `:' [<expression>]

<short_idxrange> ::= <singleidx> `:' [<expression>] 

<single_idx> ::= <expression>

<subscription> ::= single_idx 
	\alt short_idxrange 
	\alt long_idxrange 
	\alt idxlist

<slice> ::= <primary> `[' <subscription> `]'

<dotname> ::= <primary> (`.' "IDENT")$^{+}$

<primary> ::= "IDENT" | <dotname> | <slice> | <call>

\end{grammar}

\subsection{Parser}

\pagebreak

\section{Intermediate representation}

\pagebreak

\section{Virtual machine}

\pagebreak

\section{Standard library}


\end{document}
